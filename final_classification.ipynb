{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOpkOv-vSXwN"
      },
      "source": [
        "# Treinamento Classificação de Idade Óssea (anos)\n",
        "Notebook adaptado para imagens binárias e classificação discreta em anos.\n",
        "- CSV contém colunas: `id`, `boneage`\n",
        "- Ignora coluna `male`\n",
        "- Relatórios finais: Classification Report + Matriz de Confusão"
      ],
      "id": "tOpkOv-vSXwN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gg1-jLUpSXwO"
      },
      "outputs": [],
      "source": [
        "# =========================================================\n",
        "# Instalar dependências\n",
        "# =========================================================\n",
        "!pip install timm albumentations pandas scikit-learn matplotlib seaborn tqdm torch torchvision"
      ],
      "id": "gg1-jLUpSXwO"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6tIRpNPJTbcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec87193b-f847-4169-e8d1-80915355ef44"
      },
      "id": "6tIRpNPJTbcb",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Descompactar zip\n",
        "# =========================================================\n",
        "\n",
        "!unzip /content/drive/MyDrive/TCC/famele_380x380.zip -d /content/saida2"
      ],
      "metadata": {
        "id": "vsQ19ezSTUd-"
      },
      "id": "vsQ19ezSTUd-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Hnk_hMYvSXwP"
      },
      "outputs": [],
      "source": [
        "import os, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "import timm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2"
      ],
      "id": "Hnk_hMYvSXwP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oA9I-KbwSXwP"
      },
      "outputs": [],
      "source": [
        "# =========================================================\n",
        "# Carregar CSV\n",
        "# =========================================================\n",
        "csv_path = \"/content/famele_gruped_classification_training.csv\"  # adapte o caminho\n",
        "img_dir = \"/content/saida2/b380x380\"  # adapte o caminho\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "df['boneage'] = df['boneage'].astype(int)\n",
        "print(df.head())\n",
        "num_classes = df['boneage'].nunique()\n",
        "print('Número de classes:', num_classes)"
      ],
      "id": "oA9I-KbwSXwP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLl_0g6xSXwQ"
      },
      "outputs": [],
      "source": [
        "# =========================================================\n",
        "# Data Augmentation com Albumentations\n",
        "# =========================================================\n",
        "train_tfms = A.Compose([\n",
        "    A.Resize(380, 380),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.7),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.CLAHE(clip_limit=2.0, p=0.3),\n",
        "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "val_tfms = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
        "    ToTensorV2()\n",
        "])"
      ],
      "id": "KLl_0g6xSXwQ"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vo264w30SXwQ"
      },
      "outputs": [],
      "source": [
        "# =========================================================\n",
        "# Dataset adaptado\n",
        "# =========================================================\n",
        "class BoneAgeDataset(Dataset):\n",
        "    def __init__(self, df, img_dir, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = os.path.join(self.img_dir, f\"{row['id']}.png\")\n",
        "        image = np.array(Image.open(img_path).convert(\"L\"))  # grayscale\n",
        "\n",
        "        label = int(row[\"boneage\"])\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)[\"image\"]\n",
        "\n",
        "        return image, label\n"
      ],
      "id": "vo264w30SXwQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8byqgflSXwQ"
      },
      "outputs": [],
      "source": [
        "# =========================================================\n",
        "# Split estratificado\n",
        "# =========================================================\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, val_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    stratify=df['boneage'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_ds = BoneAgeDataset(train_df, img_dir, transform=train_tfms)\n",
        "val_ds = BoneAgeDataset(val_df, img_dir, transform=val_tfms)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
        "\n",
        "# =========================================================\n",
        "# Modelo EfficientNet-B4 com Dropout + Fine-tuning parcial\n",
        "# =========================================================\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# cria o modelo base\n",
        "backbone = timm.create_model(\n",
        "    'efficientnet_b4',\n",
        "    pretrained=True,\n",
        "    num_classes=num_classes,\n",
        "    in_chans=1   # importante se suas imagens forem grayscale\n",
        ")\n",
        "\n",
        "# congelar quase tudo\n",
        "for param in backbone.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# descongelar últimas camadas\n",
        "for param in backbone.blocks[-1].parameters():   # último bloco do EfficientNet\n",
        "    param.requires_grad = True\n",
        "for param in backbone.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# substituir classifier\n",
        "in_features = backbone.classifier.in_features\n",
        "backbone.classifier = nn.Sequential(\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(in_features, num_classes)\n",
        ")\n",
        "\n",
        "model = backbone.to(device)\n",
        "\n",
        "# loss e otimizador\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "\n",
        "# scheduler\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode=\"min\",\n",
        "    factor=0.5,\n",
        "    patience=2\n",
        ")"
      ],
      "id": "O8byqgflSXwQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Funções de treino/validação\n",
        "# =========================================================\n",
        "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    loop = tqdm(loader, desc=\"Treinando\", leave=False)\n",
        "    for imgs, labels in loop:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * imgs.size(0)\n",
        "        _, preds = outputs.max(1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # mostra andamento da época\n",
        "        loop.set_postfix({\n",
        "            \"loss\": f\"{running_loss/total:.4f}\",\n",
        "            \"acc\": f\"{correct/total:.4f}\"\n",
        "        })\n",
        "\n",
        "    return running_loss/total, correct/total\n",
        "\n",
        "\n",
        "def validate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    loop = tqdm(loader, desc=\"Validando\", leave=False)\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in loop:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * imgs.size(0)\n",
        "            _, preds = outputs.max(1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            # mostra andamento da época\n",
        "            loop.set_postfix({\n",
        "                \"loss\": f\"{running_loss/total:.4f}\",\n",
        "                \"acc\": f\"{correct/total:.4f}\"\n",
        "            })\n",
        "\n",
        "    return running_loss/total, correct/total"
      ],
      "metadata": {
        "id": "WSTarzbmUoFI"
      },
      "id": "WSTarzbmUoFI",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# criar a coluna corretamente\n",
        "df[\"boneage_year\"] = df[\"boneage\"]\n",
        "\n",
        "# verificar distribuição\n",
        "print(\"Distribuição por idade (anos):\")\n",
        "print(df[\"boneage_year\"].value_counts().sort_index())\n"
      ],
      "metadata": {
        "id": "-gOyIG5UaWp_"
      },
      "id": "-gOyIG5UaWp_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKEn24lISXwR"
      },
      "outputs": [],
      "source": [
        "# =========================================================\n",
        "# Loop de Treinamento com Early Stopping + Scheduler\n",
        "# =========================================================\n",
        "EPOCHS = 100\n",
        "PATIENCE = 5\n",
        "best_val_loss = float(\"inf\")\n",
        "best_acc = 0\n",
        "epochs_no_improve = 0\n",
        "\n",
        "history = {\"train_loss\":[], \"val_loss\":[], \"train_acc\":[], \"val_acc\":[]}\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\n===== Época {epoch+1}/{EPOCHS} =====\", flush=True)\n",
        "\n",
        "    # Treino\n",
        "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "\n",
        "    # Validação\n",
        "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
        "\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['val_acc'].append(val_acc)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\", flush=True)\n",
        "\n",
        "    # Scheduler\n",
        "    scheduler.step(val_loss)\n",
        "    print(f\"Learning Rate atual: {optimizer.param_groups[0]['lr']}\", flush=True)\n",
        "\n",
        "    # Early Stopping\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"/content/best_model.pth\")\n",
        "        print(\"Modelo salvo!\", flush=True)\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        print(f\"Nenhuma melhora em {epochs_no_improve} época(s).\", flush=True)\n",
        "\n",
        "    if epochs_no_improve >= PATIENCE:\n",
        "        print(\"Early stopping acionado!\", flush=True)\n",
        "        break\n"
      ],
      "id": "mKEn24lISXwR"
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Relatórios finais\n",
        "# =========================================================\n",
        "model.load_state_dict(torch.load(\"/content/best_model.pth\"))\n",
        "model.eval()\n",
        "\n",
        "all_labels, all_preds = [], []\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in val_loader:\n",
        "        imgs = imgs.to(device)\n",
        "        outputs = model(imgs)\n",
        "        _, preds = outputs.max(1)\n",
        "        all_labels.extend(labels.numpy())\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "print(\"== Classification Report ==\")\n",
        "print(classification_report(all_labels, all_preds))\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predito')\n",
        "plt.ylabel('Verdadeiro')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SFtP4gkId09D"
      },
      "id": "SFtP4gkId09D",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}